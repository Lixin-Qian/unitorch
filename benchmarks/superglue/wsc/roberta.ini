[core/cli]
task_name = core/task/supervised_task
depends_templates = ['benchmarks/glue']
from_ckpt_dir = ./roberta
cache_dir = ./roberta

# model
[benchmarks/model/classification/winograd]
model_name = roberta
config_path = https://huggingface.co/roberta-base/resolve/main/config.json
pretrained_weight_path = https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin
gradient_checkpointing = False

# dataset
[benchmarks/dataset/superglue/wsc]
processor_name = roberta
vocab_path = https://huggingface.co/roberta-base/resolve/main/vocab.json
merge_path = https://huggingface.co/roberta-base/resolve/main/merges.txt
max_num_cands = 10

[core/optim/adam]
learning_rate = 0.000003

[core/scheduler/linear_warmup]
num_warmup_rate = 0.0001

# task
[core/task/supervised_task]
model = benchmarks/model/classification/winograd
optim = core/optim/adam
scheduler = core/scheduler/linear_warmup
dataset = benchmarks/dataset/superglue/wsc
score_fn = core/score/acc
monitor_fns = ['core/score/acc']
output_header = ['text', 'span1_index', 'span1_text', 'span2_index', 'span2_text', 'idx']
post_process_fn = core/postprocess/binary_score
writer_fn = core/writer/csv

from_ckpt_dir = ${core/cli:from_ckpt_dir}
to_ckpt_dir = ${core/cli:cache_dir}
output_path = ${core/cli:cache_dir}/output.txt

epochs = 40

train_batch_size = 16
dev_batch_size = 16
test_batch_size = 16
