[core/cli]
task_name = core/task/supervised_task
from_ckpt_dir = ./roberta
cache_dir = ./roberta

# model
[core/model/classification/roberta]
pretrained_name = roberta-large
gradient_checkpointing = True
num_class = 3

# dataset
[core/dataset/ast]
# data columns: premise, hypothesis, label, idx
data_name = glue
config_name = mnli

[core/dataset/ast/train]
preprocess_functions = ['core/process/roberta_classification(premise, hypothesis)', 'core/process/label(label)']

[core/dataset/ast/dev]
split = validation_matched
preprocess_functions = ['core/process/roberta_classification(premise, hypothesis)', 'core/process/label(label)']

[core/dataset/ast/test]
split = test_matched
preprocess_functions = ['core/process/roberta_classification(premise, hypothesis)']

# process
[core/process/roberta]
pretrained_name = roberta-large
max_seq_length = 128

[core/process/general]
num_class = 3

[core/optim/adamw]
learning_rate = 0.000003

[core/scheduler/linear_warmup]
num_warmup_rate = 0.0001

# task
[core/task/supervised_task]
model = core/model/classification/roberta
optim = core/optim/adamw
scheduler = core/scheduler/linear_warmup
dataset = core/dataset/ast
loss_fn = core/loss/ce
score_fn = core/score/acc
monitor_fns = ['core/score/acc']
output_header = ['premise', 'hypothesis', 'idx']
post_process_fn = core/postprocess/classifier_score
writer_fn = core/writer/csv

from_ckpt_dir = ${core/cli:from_ckpt_dir}
to_ckpt_dir = ${core/cli:cache_dir}
output_path = ${core/cli:cache_dir}/output.txt

epochs = 10

train_batch_size = 128
dev_batch_size = 256
test_batch_size = 256
