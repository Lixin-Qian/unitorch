[core/cli]
task_name = core/task/supervised_task
from_ckpt_dir = ./roberta
cache_dir = ./roberta

# model
[core/model/classification/roberta]
pretrained_name = roberta-large
gradient_checkpointing = True
num_class = 2

# dataset
[core/dataset/ast]
# data columns: sentence, label, idx
data_name = glue
config_name = cola

[core/dataset/ast/train]
preprocess_functions = ['core/process/roberta_classification(sentence)', 'core/process/label(label)']

[core/dataset/ast/dev]
preprocess_functions = ['core/process/roberta_classification(sentence)', 'core/process/label(label)']

[core/dataset/ast/test]
preprocess_functions = ['core/process/roberta_classification(sentence)']

# process
[core/process/roberta]
pretrained_name = roberta-large
max_seq_length = 128

[core/process/general]
num_class = 2

[core/optim/adamw]
learning_rate = 0.000003

# task
[core/task/supervised_task]
model = core/model/classification/roberta
optim = core/optim/adamw
dataset = core/dataset/ast
loss_fn = core/loss/ce
score_fn = core/score/mattcorr
monitor_fns = ['core/score/acc', 'core/score/mattcorr']
output_header = ['sentence', 'idx']
post_process_fn = core/postprocess/classifier_score
writer_fn = core/writer/csv

from_ckpt_dir = ${core/cli:from_ckpt_dir}
to_ckpt_dir = ${core/cli:cache_dir}
output_path = ${core/cli:cache_dir}/output.txt

epochs = 40

train_batch_size = 128
dev_batch_size = 256
test_batch_size = 256
